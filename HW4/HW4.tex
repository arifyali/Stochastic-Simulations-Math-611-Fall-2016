\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{amscd, amssymb, amsmath, verbatim, setspace}
\usepackage[left=1.0in, right=1.0in, top=1.0in, bottom=1.0in]{geometry}
\usepackage{mathrsfs}
\usepackage{listings}


\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\begin{flushright}
Arif Ali\\
Math 611 Stochastic Simulation\\
Sept 29, 2016\\
\end{flushright}

\begin{center}
\LARGE\textbf{Homework 4}
  \end{center}
\section*{Exercise 1}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{h} \hlkwb{=} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}
  \hlkwd{exp}\hlstd{(}\hlopt{-}\hlstd{x)}\hlopt{/}\hlstd{(}\hlnum{1}\hlopt{+}\hlstd{x}\hlopt{^}\hlnum{2}\hlstd{)}
\hlstd{\}}
\hlstd{n} \hlkwb{=} \hlnum{1e4}

\hlstd{H} \hlkwb{=} \hlkwd{integrate}\hlstd{(h,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
The analytical evaluation of $\int_{0}^{1} \frac{e^{-x}}{(1+x^2)} \delta x$ is 0.5247971.
\subsection*{Part A}
\begin{equation}
  F_X(x) = c \int_{0}^{x} 1 \delta t = c \big|_0^x t = cx 
\end{equation}

\begin{equation}
  1 = F_X(1) = c*1 \implies c = 1 \therefore F_X(x) = x
\end{equation}

\begin{equation}
  \hat{I} = \int_{0}^{1} \frac{exp(-x)}{1+x^2}*1/1 dx \approx \frac{1}{n}\sum_{i=1}^{n} \frac{e^{-x}}{1+x^2}
\end{equation}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{u} \hlkwb{=} \hlkwd{runif}\hlstd{(n,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{)}
\hlstd{x} \hlkwb{=} \hlstd{u} \hlcom{# F^-1(x) = x}
\hlstd{I_hat} \hlkwb{=} \hlkwd{h}\hlstd{(x)}
\hlkwd{summary}\hlstd{(I_hat)}
\end{alltt}
\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.1840  0.3057  0.4894  0.5281  0.7355  1.0000
\end{verbatim}
\begin{alltt}
\hlkwd{var}\hlstd{(I_hat)}
\end{alltt}
\begin{verbatim}
## [1] 0.06001488
\end{verbatim}
\end{kframe}
\end{knitrout}
\subsection*{Part B}
\begin{equation}
\begin{split}
  G_{X}(x) = c*\int_{0}^{x} \frac{e^{-x}}{1-e^{-1}} \delta x =\\
  c*\frac{1}{1-e^{-1}}\int_{0}^{x} e^{-x} \delta x =\\ 
  c * \frac{1}{1-e^{-1}}*(1-e^{-x})
\end{split}
\end{equation}

\begin{equation}
1 = G_X(1) = c * \frac{1}{1-e^{-1}}*(1-e^{-1}) = c \implies c = 1 \therefore G(x) = \frac{1}{1-e^{-1}}*(1-e^{-x})
\end{equation}

To find $G^{-1}(x)$, we do the following:
\begin{equation}
\begin{split}
y = \frac{1}{1-e^{-1}}*(1-e^{-x}) \implies \\
y*(1-e^{-1}) = 1 - e^{-x} \implies \\
1 - y*(1-e^{-1}) = e^{-x} \implies \\
ln(1 - y*(1-e^{-1})) = -x \implies \\
x = -ln(1 - y*(1-e^{-1})) \\
\therefore G^{-1}(x) = -ln(1 - x*(1-e^{-1}))
\end{split}
\end{equation}

\begin{equation}
\begin{split}
  \hat{I} = \int_{0}^{1} \frac{exp(-x)}{1+x^2}*\frac{1}{(\frac{e^{-x}}{1-e^{-1}})} dx \approx \\
  \frac{1}{n}\sum_{i=1}^{n} \frac{\frac{e^{-x}}{1+x^2}}{\frac{e^{-x}}{1-e^{-1}}} = \\
  \frac{1-e^{-1}}{n}\sum_{i=1}^{n}\frac{1}{1+x^2}
  \end{split}
\end{equation}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{u} \hlkwb{=} \hlkwd{runif}\hlstd{(n,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{)}
\hlstd{x} \hlkwb{=} \hlopt{-}\hlkwd{log}\hlstd{(}\hlnum{1}\hlopt{-}\hlstd{u}\hlopt{*}\hlstd{(}\hlnum{1}\hlopt{-}\hlkwd{exp}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{)))} \hlcom{#G^-1(U)}

\hlstd{I_hat} \hlkwb{=} \hlstd{(}\hlnum{1}\hlopt{-}\hlkwd{exp}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{))}\hlopt{*}\hlstd{(}\hlnum{1}\hlopt{/}\hlstd{(}\hlnum{1}\hlopt{+}\hlstd{x}\hlopt{^}\hlnum{2}\hlstd{))}
\hlkwd{summary}\hlstd{(I_hat)}
\end{alltt}
\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.3161  0.4455  0.5513  0.5236  0.6134  0.6321
\end{verbatim}
\begin{alltt}
\hlkwd{var}\hlstd{(I_hat)}
\end{alltt}
\begin{verbatim}
## [1] 0.009490023
\end{verbatim}
\end{kframe}
\end{knitrout}
\section*{Exercise 2}
If $\int_{0}^{1} exp(x) \delta x$ is evaluated analytically, the result is 1.7182818.

For the antithetic variable appoarch let $h(x) = e^{x}$ and $f(x) = 1$
\begin{equation}
  \begin{split}
  F(x) = \int_{0}^{x} 1 \delta x = x \implies F^{-1}(x) =x
  \end{split}
\end{equation}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{MCint} \hlkwb{=} \hlkwa{function}\hlstd{(}\hlkwc{n} \hlstd{=}\hlnum{1e4}\hlstd{,} \hlkwc{a}\hlstd{,} \hlkwc{b}\hlstd{,} \hlkwc{f}\hlstd{)\{}
  \hlstd{x} \hlkwb{=} \hlkwd{runif}\hlstd{(n, a, b)}
  \hlstd{y} \hlkwb{=} \hlkwd{f}\hlstd{(x)}
  \hlkwd{return}\hlstd{((b}\hlopt{-}\hlstd{a)}\hlopt{*}\hlstd{(y))}
\hlstd{\}}
\hlstd{n} \hlkwb{=} \hlnum{1e3}
\hlstd{U} \hlkwb{=} \hlkwd{runif}\hlstd{(n,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)}
\hlstd{X} \hlkwb{=} \hlstd{U}
\hlstd{Y} \hlkwb{=} \hlnum{1} \hlopt{-} \hlstd{U}
\hlstd{anti} \hlkwb{=} \hlnum{1}\hlopt{/}\hlstd{(}\hlnum{2}\hlstd{)}\hlopt{*}\hlstd{(}\hlkwd{exp}\hlstd{(U)}\hlopt{+}\hlkwd{exp}\hlstd{(}\hlnum{1}\hlopt{-}\hlstd{U))}
\hlstd{MC} \hlkwb{=} \hlkwd{MCint}\hlstd{(n,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{,} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{exp}\hlstd{(x)\})}

\hlkwd{var}\hlstd{(anti)} \hlopt{<} \hlkwd{var}\hlstd{(MC)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\end{kframe}
\end{knitrout}
The percent reduction in variance is approximately 98.3752672\%.

When 1000 estimates using the antithetic variable appoarch and MC integration
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{anti} \hlkwb{=} \hlkwd{c}\hlstd{()}
\hlstd{MC} \hlkwb{=} \hlkwd{c}\hlstd{()}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{1000}\hlstd{)\{}
  \hlstd{n} \hlkwb{=} \hlnum{1e3}
  \hlstd{U} \hlkwb{=} \hlkwd{runif}\hlstd{(n,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)}
  \hlstd{X} \hlkwb{=} \hlstd{U}
  \hlstd{Y} \hlkwb{=} \hlnum{1} \hlopt{-} \hlstd{U}
  \hlstd{anti[i]} \hlkwb{=} \hlkwd{mean}\hlstd{(}\hlnum{1}\hlopt{/}\hlstd{(}\hlnum{2}\hlstd{)}\hlopt{*}\hlstd{(}\hlkwd{exp}\hlstd{(U)}\hlopt{+}\hlkwd{exp}\hlstd{(}\hlnum{1}\hlopt{-}\hlstd{U)))}
  \hlstd{MC[i]} \hlkwb{=} \hlkwd{mean}\hlstd{(}\hlkwd{MCint}\hlstd{(n,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{,} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{exp}\hlstd{(x)\}))}
 \hlstd{\}}
\hlkwd{var}\hlstd{(anti)} \hlopt{<} \hlkwd{var}\hlstd{(MC)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\begin{alltt}
\hlstd{(}\hlkwd{var}\hlstd{(MC)} \hlopt{-} \hlkwd{var}\hlstd{(anti))}\hlopt{/}\hlkwd{var}\hlstd{(MC)}\hlopt{*}\hlnum{100}
\end{alltt}
\begin{verbatim}
## [1] 98.61364
\end{verbatim}
\end{kframe}
\end{knitrout}
The percent reduction in variance is approximately 98.6136392\%.

\section*{Exercise 3}
States $1$ and $5$ are transient because there are one or more ways in which their states can never return.

States $2$, $3$, and $4$ are recurrent.

$\{2,4\}$ is a closed set that is irreducible. 
\section*{Exercise 4}
\begin{equation}
  \begin{split}
  \left(\begin{array}{cccc}
p_{1} & p_{2} & p_{3} & p_{4}\end{array}\right)\left(\begin{array}{cccc}
0.7 & 0 & 0.3 & 0\\
0.6 & 0 & 0.4 & 0\\
0 & 0.5 & 0 & 0.5\\
0 & 0.4 & 0 & 0.6
\end{array}\right)=\left(\begin{array}{cccc}
p_{1} & p_{2} & p_{3} & p_{4}\end{array}\right) \implies \\
\left(\begin{array}{c}
0.7p_{1}+0.6p_{2}\\
0.4p_{3}+0.4p_{4}\\
0.3p_{1}+0.4p_{2}\\
0.5p_{3}+0.6p_{4}
\end{array}\right)=\left(\begin{array}{c}
p_{1}\\
p_{2}\\
p_{3}\\
p_{4}
\end{array}\right)
  \end{split}
\end{equation}

From the matrix we can see $p_{1} = 2p_2$ and $0.6p_{1}+0.4p_2=p_3\implies p_2=p_3$ and $0.5p_3+0.6p_4=p_4 \implies p_4 =1.25p_3$

Since $p_1+p_2+p_3+p_4 =1 = 2p_3+p_3+p_3+1.25p_3 = 1 \implies p_3 = \frac{1}{5.25}$
\begin{equation}
\begin{split}
p_1 = 2/5.25 \\
p_2 = 1/5.25 \\ 
p_4 = 1.25/5.25 \\
\end{split}
\end{equation}
The stationary distribution is $\left(\begin{array}{cccc}
\frac{2}{5.25} & \frac{1}{5.25} & \frac{1}{5.25} & \frac{1.25}{5.25}\end{array}\right)$.
\section*{Exercise 5}
We know that $X_{n}\sim poisson(t)$ and $X_{n+1} = \psi_{n+1}+R(X_{n})$ where $\psi_{n+1} \sim poisson(\lambda)$ and $R(X_{n}) \sim poisson(pt)$. The addition of two poisson variables combines the lambda values so $X_{n+1} \sim poisson(\lambda + pt)$. In order for the stationary distribution to work $X_{n} = X_{n+1}$

\begin{equation}
  \begin{split}
  t = \lambda + pt \implies \\
  t - pt = \lambda \implies \\
  t(1-p) = \lambda \implies \\
  t = \frac{\lambda}{1-p}
  \end{split}
\end{equation}

$\therefore$ the stationary distribution is $poisson(\frac{\lambda}{1-p})$
\end{document}
